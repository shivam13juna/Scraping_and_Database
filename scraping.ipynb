{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Begin \"How to Learn Scraping\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import socket\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import xml.etree.ElementTree as ET\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginning a tad revision of regular expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'From: and To: are important constructs'\n",
    "line = base.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: <re.Match object; span=(0, 5), match='From:'>\n",
      "String:  1\n"
     ]
    }
   ],
   "source": [
    "# How we can use re.search and find\n",
    "\n",
    "print(\"Regular:\", re.search('From:', line))\n",
    "print(\"String: \", line.find('rom:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular:  <re.Match object; span=(0, 5), match='From:'>\n",
      "String:  True\n"
     ]
    }
   ],
   "source": [
    "# How we can use re.search and startswith\n",
    "\n",
    "print(\"Regular: \", re.search('^From:', line))\n",
    "print(\"String: \", line.startswith('From:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Match\n"
     ]
    }
   ],
   "source": [
    "if re.match('^.*@(gmail|google)\\.(com)$', 'shivam13juna@gmail.com'):\n",
    "    print(\"Found Match\")\n",
    "else:\n",
    "    print(\"Didn't find match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 8), match='X-Sieve:'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'X-plane is behind schedule:'\n",
    "line1 = 'X-Sieve:'\n",
    "re.match('X-^\\s+:', line1)\n",
    "re.match('X-\\S+:', line1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '19', '42']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n^F.+?: is non greedy matching\\n^F.+: is greedy matching\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrating find all\n",
    "\n",
    "x = 'My 2 favorite numbers are 19 and 42'\n",
    "y = re.findall('[0-9]+', x)\n",
    "print(y)\n",
    "\n",
    "\n",
    "'''\n",
    "^F.+?: is non greedy matching\n",
    "^F.+: is greedy matching\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stephen.marquard@uct.ac.za']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\S+?@\\S+', 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = 'Why should you learn to write programs? 7746 \\\n",
    "12 1929 8827\\\n",
    "Writing programs (or programming) is a very creative \\\n",
    "7 and rewarding activity.  You can write programs for \\\n",
    "many reasons, ranging from making your living to solving\\\n",
    "8837 a difficult data analysis problem to having fun to helping 128\\\n",
    "someone else solve a problem.  This book assumes that \\\n",
    "everyone needs to know how to program ...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum was:  27486\n"
     ]
    }
   ],
   "source": [
    "total_sum = 0\n",
    "for i in re.findall('\\d+', store):\n",
    "    total_sum += int(i)\n",
    "    \n",
    "print(\"Total sum was: \", total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum is:  475263\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file = ''.join(list(open('data.txt', 'r')))\n",
    "\n",
    "print(\"Total sum is: \", sum(list(map(lambda x: int(x), re.findall('\\d+', file)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with Sockets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('www.data.pr4e.org', 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Tue, 21 Jul 2020 12:19:36 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"a7-54f6609245537\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 167\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    data = mysock.recv(1024)\n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode())\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with URLLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "# The way we read file off the internet is\n",
    "\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'But soft what light through yonder window breaks\\nIt is the east and Juliet is the sun\\nArise fair sun and kill the envious moon\\nWho is already sick and pale with grief\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add .read() if you wanna do it all in one hit\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt').read()\n",
    "\n",
    "fhand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with Beautiful Soup now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://data.pr4e.org/romeo.txt'\n",
    "html = urllib.request.urlopen(url).read()\n",
    "\n",
    "# This is how beautiful soup parses all the html content\n",
    "soup = BeautifulSoup(html, 'html.parser') # ad-hoc heuristic\n",
    "\n",
    "# Let's try retrieving all the anchor tags\n",
    "tags = soup('a') # Gimme list of all the anchor tags in the code\n",
    "\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None)) # Gonna pull out the text in href, so either pull href or None\n",
    "    \n",
    "\n",
    "# How someone can access other entities from soup object\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "# tags = soup('a')\n",
    "# for tag in tags:\n",
    "#    # Look at the parts of a tag\n",
    "#    print 'TAG:',tag\n",
    "#    print 'URL:',tag.get('href', None)\n",
    "#    print 'Contents:',tag.contents[0]\n",
    "#    print 'Attrs:',tag.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trick for ignoring SSL errors (HTTPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.learnerprivacy.org/\n",
      "https://www.si.umich.edu/\n",
      "https://www.ratemyprofessors.com/ShowRatings.jsp?tid=1159280\n",
      "https://www.learnerprivacy.org\n",
      "https://www.dr-chuck.com/csev-blog/\n",
      "https://www.twitter.com/drchuck/\n",
      "https://www.dr-chuck.com/dr-chuck/resume/speaking.htm\n",
      "https://www.slideshare.net/csev\n",
      "/dr-chuck/resume/index.htm\n",
      "https://amzn.to/1K5Q81K\n",
      "https://www.coursera.org/instructor/drchuck\n",
      "http://afs.dr-chuck.com/papers/\n",
      "https://itunes.apple.com/us/podcast/computing-conversations/id731495760\n",
      "https://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "https://developers.imsglobal.org/\n",
      "https://www.youtube.com/user/csev\n",
      "https://vimeo.com/drchuck/videos\n",
      "https://backpack.openbadges.org/share/4f76699ddb399d162a00b89a452074b3/\n",
      "https://www.linkedin.com/in/charlesseverance/\n",
      "https://www.researchgate.net/profile/Charles_Severance/\n",
      "https://www.learnerprivacy.org/\n",
      "https://www.py4e.com/\n",
      "https://www.dj4e.com/\n",
      "https://www.wa4e.com/\n",
      "https://www.coursera.org/course/insidetheinternet\n",
      "https://www.sakaiproject.org/\n",
      "https://www.tsugi.org/\n",
      "https://developers.imsglobal.org/\n",
      "http://www.py4e.com/book\n",
      "/sakai-book\n",
      "http://www.amazon.com/gp/product/1624311393/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1624311393&linkCode=as2&tag=drchu02-20\n",
      "http://www.amazon.com/gp/product/059680069X/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=059680069X&linkCode=as2&tag=drchu02-20\n",
      "http://www.amazon.com/Performance-Computing-Architectures-Optimization-Benchmarks/dp/156592312X/\n",
      "http://oreilly.com/catalog/9781565923126/\n",
      "http://cnx.org/content/col11136/latest/\n",
      "http://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "https://www.vimeo.com/17207620\n",
      "https://www.youtube.com/watch?v=BVKpW02hsrU\n",
      "https://www.youtube.com/watch?v=sa2WsgCvn7c\n",
      "https://www.vimeo.com/17213019\n",
      "https://www.youtube.com/watch?v=FJ078sO35M0\n",
      "http://afs.dr-chuck.com/citoolkit\n",
      "https://twitter.com/drchuck\n"
     ]
    }
   ],
   "source": [
    "url = 'http://dr-chuck.com'\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "tags = soup('a') \n",
    "\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None)) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum is:  2395\n"
     ]
    }
   ],
   "source": [
    "# Graded assignment\n",
    "\n",
    "url = 'http://py4e-data.dr-chuck.net/comments_821796.html'\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "tags = soup('span') \n",
    "\n",
    "print(\"Total sum is: \", sum(list(map(lambda x: int(x.contents[0]), tags))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graded Assignment\n",
    "    \n",
    "url = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html'\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "tags = soup('a') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = list(map(lambda x: x.get('href'), tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://py4e-data.dr-chuck.net/known_by_Montgomery.html'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fikret\n",
      "Montgomery\n",
      "Mhairade\n",
      "Butchi\n"
     ]
    }
   ],
   "source": [
    "count = 3\n",
    "nex = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html'\n",
    "while count >= 0:\n",
    "    print(nex.split('_')[-1].split('.')[0])\n",
    "    nex = list(map(lambda x: x.get('href'), BeautifulSoup(urllib.request.urlopen(nex, context=ctx).read(), 'html.parser')('a')))[2]\n",
    "    count-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majid\n",
      "Alba\n",
      "Armaan\n",
      "Temilade\n",
      "Reno\n",
      "Muriel\n",
      "Lilliarna\n",
      "Adana\n"
     ]
    }
   ],
   "source": [
    "count = 7\n",
    "nex = 'http://py4e-data.dr-chuck.net/known_by_Majid.html'\n",
    "while count >= 0:\n",
    "    print(nex.split('_')[-1].split('.')[0])\n",
    "    nex = list(map(lambda x: x.get('href'), BeautifulSoup(urllib.request.urlopen(nex, context=ctx).read(), 'html.parser')('a')))[17]\n",
    "    count-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anayah'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nex.split('_')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match('\\.html', nex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing XML Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  Chuck\n",
      "Attr:  yes\n"
     ]
    }
   ],
   "source": [
    "# Example of single line tag\n",
    "\n",
    "data = '''\n",
    "<person>\n",
    "    <name>Chuck</name>\n",
    "    <phone type='int1'>\n",
    "        +1 734 303 4456\n",
    "    </phone>\n",
    "    <email hide=\"yes\"/>\n",
    "</person>\n",
    "'''\n",
    "\n",
    "tree = ET.fromstring(data)\n",
    "print('Name: ', tree.find('name').text)\n",
    "print('Attr: ', tree.find('email').get('hide'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Count:  2\n",
      "Name Chuck\n",
      "Id 001\n",
      "Attribute 2\n",
      "Name Brent\n",
      "Id 009\n",
      "Attribute 7\n"
     ]
    }
   ],
   "source": [
    "# Example of multi line tag\n",
    "\n",
    "input = '''\n",
    "<stuff>\n",
    "    <users>\n",
    "        <user x='2'>\n",
    "            <id>001</id>\n",
    "            <name>Chuck</name>\n",
    "        </user>\n",
    "        <user x='7'>\n",
    "            <id>009</id>\n",
    "            <name>Brent</name>\n",
    "        </user>\n",
    "    </users>\n",
    "</stuff>\n",
    "    \n",
    "'''\n",
    "\n",
    "stuff = ET.fromstring(input)\n",
    "lst = stuff.findall('users/user')\n",
    "print('User Count: ', len(lst))\n",
    "\n",
    "for item in lst:\n",
    "    print('Name', item.find('name').text)\n",
    "    print('Id', item.find('id').text)\n",
    "    print('Attribute', item.get('x'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Count:  50\n",
      "Total sum was:  2723\n"
     ]
    }
   ],
   "source": [
    "# Graded assignment\n",
    "\n",
    "url = 'http://py4e-data.dr-chuck.net/comments_821798.xml'\n",
    "xml = urllib.request.urlopen(url, context=ctx).read().decode()\n",
    "\n",
    "stuff = ET.fromstring(xml)\n",
    "lst = stuff.findall('comments/comment')\n",
    "print('User Count: ', len(lst))\n",
    "\n",
    "total_sum = 0\n",
    "\n",
    "for item in lst:\n",
    "    total_sum += int(item.find('count').text)\n",
    "    \n",
    "print(\"Total sum was: \", total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum is:  2286\n"
     ]
    }
   ],
   "source": [
    "# Graded Assignment\n",
    "\n",
    "content = urllib.request.urlopen('http://py4e-data.dr-chuck.net/comments_821799.json').read().decode()\n",
    "\n",
    "data = json.loads(content)\n",
    "\n",
    "total_sum = 0\n",
    "\n",
    "for i in data['comments']:\n",
    "    total_sum += i['count']\n",
    "\n",
    "print(\"Total sum is: \", total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving http://py4e-data.dr-chuck.net/json?address=Warsaw+University&key=42\n",
      "Retrieved 2331 characters\n",
      "Place id is:  ChIJCWP6Nl7MHkcRf_xabKDNoaQ\n"
     ]
    }
   ],
   "source": [
    "# Graded Assignment\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "import ssl\n",
    "\n",
    "api_key = False\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# while True:\n",
    "address = 'Warsaw University'\n",
    "\n",
    "parms = dict()\n",
    "parms['address'] = address\n",
    "if api_key is not False: parms['key'] = api_key\n",
    "url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "print('Retrieving', url)\n",
    "uh = urllib.request.urlopen(url, context=ctx)\n",
    "data = uh.read().decode()\n",
    "print('Retrieved', len(data), 'characters')\n",
    "\n",
    "try:\n",
    "    js = json.loads(data)\n",
    "except:\n",
    "    js = None\n",
    "\n",
    "print(\"Place id is: \", js['results'][0]['place_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Brahma Kumaris site for downloading all murlis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request('https://madhubanmurli.org', headers={'User-Agent': 'Chrome/84.0.4147.89'})\n",
    "html = urllib.request.urlopen(req).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req = urllib.request.Request('https://madhubanmurli.org', headers={'User-Agent': 'Chrome/84.0.4147.89'})\n",
    "html = urllib.request.urlopen(req).read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "tags = soup('div')\n",
    "# tags = soup.findAll(\"div\", {\"class\": \"murli-body\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tags:\n",
    "    if 'murli-body' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll(\"div\", {\"class\": \"stylelistrow\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys \n",
    "\n",
    "for foo in soup.find_all('div', attrs={'class': 'foo'}):\n",
    "    bar = foo.find('div', attrs={'class': 'bar'})\n",
    "    print(bar.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
